{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About me: Vikrant Singh Tomar, Ph.D.","text":""},{"location":"#how-to-connect","title":"How to connect","text":"<ul> <li>LinkedIn</li> <li>Chat on Matrix: @vktt:matrix.org</li> <li>Twitter{target=blank} (_not very active)</li> </ul> <ul> <li>Semantic Scholar</li> <li>Google Scholar</li> </ul>"},{"location":"#profile-summary","title":"Profile Summary","text":"<ul> <li>Currently building Avsr AI: Autonomous versatile social robotics. </li> <li>I am an experienced, driven, and entrepreneurial professional with extensive background in building and leading artificial-intelligence/machine-learning oragnizations.</li> <li>Built Fluent.ai inc. from zero into a well-known provider of on-device/offline speech recognition solutions.<ul> <li>Led the research and tech roadmap, patents and IP growth/acquisition plan, business as well as tech partnerships, and overall strategy of the company.</li> <li>Led the development of tiny (\u2248 40KB) deep learning models for speech recognition on low-power edge devices.</li> <li>Filed, acquired, and licensed 15+ patents; several of which have been granted.</li> <li>Built and grew partnerships with various chip manufacturers partners, such as, ARM, CEVA, DSPG, Ambiq, NXP, DSPC etc.</li> <li>Contributed to sales and business development. Negotiated OEM/ODM deals.</li> <li>Helped raise investments from angels and VCs over multiple rounds.</li> </ul> </li> <li>PhD in speech and AI.</li> <li>Active research in AI/machine learning, deep learning, tinyML.</li> </ul>"},{"location":"#more-details","title":"More details","text":"<p>Currently focused on building Avsr AI. At Avsr AI, we are creating an integrated framework for robotics that combines Generative AI for high-level planning with Reinforcement Learning for precise, low-level control. Our team has strong background in both AI and Robotics, and consists of experienced second-time entrepreneurs. With driving factors such as labor shortages, safety and increased efficiency, robotics and physical automation is potentially one of the most impactful opportunities in near future.</p> <p>Previosuly, I founded Fluent.ai and grew it, in my role as Founder and CTO, from zero to a well-known provider of speech recognition systemss. At Fluent.ai, we developed cutting-edge machine learning techniques for offline, on-device voice user interfaces targetted at tinyML, low-power embedded devices, smart-home devices, and wearables. We used a unique end-to-end spoken language understanding system. Unlike conventional speech recognition systems [speech --&gt; text --&gt; intent], these models do not require the intermediate text step and are able able to directly go from speech to intent, much like humans. </p> <p>My research interests are in the general area of artificial intelligence, language, robotics, generative networks, reinforcement learning, etc. I completed my PhD from the Department of Electrical and Computer Engineering, at McGill University, Montreal, Canada. I was associated with the speech and language research group supervised by Dr. Richard Rose [now at Google].</p> <p>Prior to joining McGill, I worked as a research fellow in the Dept. of Electrical Engineering at the Indian Institute of Technology Bombay [IIT B], Mumbai, India. I was primarily associated with the TTSL IIT Bombay Center of Excellence in Telecommunications [TICET], one of the six Telecom Centers Of Excellence [TCOE] in India. I got my B.Tech. in Information and Communication Technology [ICT] from Dhirubhai Ambani Institute of Information and Communication Technology [DA-IICT], Gandhinagar, Gujarat, India.</p>"},{"location":"#education","title":"Education","text":"<ul> <li>Ph.D., Electrical and Computer Engineering, focused on Deep Learning and Speech Recognition McGill University, Montreal, Canada,   2015</li> <li>B.Tech., Dhirubhai Ambani Institute of Information and Communication Technology [DA-IICT], Gandhinagar, Gujarat, India, May 2008</li> </ul>"},{"location":"#work-experience-summary","title":"Work Experience Summary","text":"<ul> <li>Avsr AI Inc., | CoFounder </li> <li>RaceRocksRaceRocks., Vancouver, Canada | Head of Technology | May 2023 -- Sept 2023</li> <li>Fluent.ai Inc., Montreal, QC, Canada | Founder and CTO  | May 2015 -- Oct 2022</li> <li>Nuance Comm. Inc., Montreal, QC, Canada | Research Scientist  | Sept 2013 -- Feb 2014</li> <li>Vestec Inc., Waterloo, ON, Canada | Research Scientist Consultant | May 2012 -- Dec 2012</li> <li>McGill University, Montreal, QC, Canada | Teaching Assistant and Lecturer | 2010 - 2013 [various]</li> <li>IIT Bombay, Mumbai India | Research Scholar | July 2008 - Dec 2010</li> </ul>"},{"location":"#research-interests","title":"Research Interests","text":"<ul> <li>General Artificial Intelligence</li> <li>Reinforcement Learning, Imitation Learning</li> <li>Speech and language processing including acoustic modeling, NLU, etc.</li> <li>Generative AI, Transformers, Vision + Language + Action Please refer to my recent publications for more details about my current area of work.</li> </ul>"},{"location":"#awards-and-grants-from-student-life-era","title":"Awards and Grants (from student life era)","text":"<ul> <li>J. W. McConnell Memorial Fellowship, McGill University, 2012</li> <li>McGill Engineering Doctoral Award, 2011 - 2013</li> <li>Joseph S. Stauffer Fellowship, McGill University, 2011</li> <li>Sheryl &amp; David Kerr Engineering Graduate Fellowship, McGill University, 2011</li> <li>McGill Engineering International Doctoral Award, 2011 - 2013</li> <li>JNTT TATA Scholar, 2009</li> <li>International Speech Communication Association Conference Grant, 2008</li> </ul>"},{"location":"publications/","title":"Publications","text":"<ul> <li>Semantic Scholar</li> </ul> <p>Note</p> <p>Please note that some of the published papers may be copyrighted by the respective publishing organizations, such as IEEE, Elsevier, and Wiley etc. as cited. You are advised to contact the publishing organization for final versions of the papers.</p>"},{"location":"publications/#patents","title":"Patents","text":"<ul> <li>Granted US10878807B2: \"System and method for implementing a vocal user interface by combining a speech to text system and a speech to intent system\". [Also granted in Europe]</li> <li>Granted US11049495B2: \"Method and device for automatically learning relevance of words in a speech recognition system\"</li> <li>Approved for grant US20210056958A1: \"System and method for tone recognition in spoken languages\"</li> <li>Approved for grant US20210055778A1: \"A low-power keyword spotting system\"</li> <li>Application WO2021030918A1: \"User-defined keyword spotting\"</li> <li>Application WO2021226709A1: \"Neural architecture search with imitation learning\"</li> </ul>"},{"location":"publications/#phd-thesis","title":"Ph.D. Thesis","text":"<p>Vikrant Singh Tomar, McGill University, \"Discriminative Manifold Learning for Automatic Speech Recognition\".</p>"},{"location":"publications/#publications_1","title":"Publications","text":"<ul> <li> <p>Farzaneh S Fard and Vikrant Singh Tomar, \"Expediting discovery in Neural Architecture Search by Combining Learning with Planning\", ICASSP 2021</p> </li> <li> <p>Mohamed Mhiri, Sam Myer, Vikrant Tomar, \"A low latency ASR-free end to end spoken language understanding system\", Interspeech 2020</p> </li> <li> <p>Hanwook Chung, Vikrant Tomar and Benoit Champagne, \"Deep convolutional neural network-based inverse filtering approach for speech de-reverberation}\", 2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP){target=_blank</p> </li> <li> <p>Farzaneh S Fard, Arash Rad, Vikrant Singh Tomar, \"Nasil: Neural Architecture Search with Imitation Learning\", IEEE ICASSP 2020</p> </li> <li> <p>Loren Lugosch, Mirco Ravanelli, Patrick Ignoto, Vikrant Singh Tomar, Yoshua Bengio, \"Speech Model Pre-training for End-to-End Spoken Language Understanding\", Interspeech 2019</p> </li> <li> <p>Loren Lugosch, Sam Myer and Vikrant Singh Tomar, \"DONUT: CTC-based Query-by-Example Keyword Spotting\", NeurIPS 2018 Interpretability and Robustness for Audio, Speech and Language Workshop</p> </li> <li> <p>Loren Lugosch and Vikrant Singh Tomar, \"Tone recognition using lifters and CTC\", InterSpeech 2018</p> </li> <li> <p>Sam Myer and Vikrant Singh Tomar, \"Efficient keyword spotting using time delay neural networks\", InterSpeech 2018</p> </li> <li> <p>Vincent Renkens, Vikrant Singh Tomar and Hugo Van Hamme, \"Incrementally learn the relevance of words in a dictionary for spoken language acquisition\", IEEE Spoken Language Technology 2016</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"Graph based manifold regularized deep neural networks for automatic speech recognition\", arXiv:1606.05925, 2016 Code on Github</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"Manifold Regularized Deep Neural Networks\", InterSpeech 2014, Singapore. Code on Github</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"A family of discriminative manifold learning algorithms and their application to speech recognition\", IEEE\\/ACM Transactions on Audio, Speech and Language Processing, vol. 22, no. 1, Jan 2014. DOI: 10.1109/TASLP.2013.2286906</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"Locality Sensitive Hashing for Fast Computation of Correlational Manifold Learning based Feature space Transformations\", InterSpeech 2013, Lyon, France</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"Efficient manifold learning for speech Recognition using locality sensitive hashing\", ICASSP 2013, Vancouver, Canada</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"Noise aware manifold learning for robust speech recognition\", ICASSP 2013, Vancouver, Canada.</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"A Correlational Discriminant Approach to Feature Extraction for Robust Speech Recognition\", InterSpeech 2012, Portland, Oregon, USA</p> </li> <li> <p>Vikrant Singh Tomar and Richard C. Rose, \"Application of a Locality Preserving Discriminant Analysis Approach to ASR 2012, Montreal, QC, Canada. }\",The 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA){target=_blankDownload presentation .pdf</p> </li> <li> <p>Vikrant Tomar and H. A. Patil, \"On the Development of Variable length Teager Energy Operator (VTEO){target=_blank}\", Interspeech 2008, Brisbane, Australia, pp.1056 - 1059</p> </li> <li> <p>H. Venkataraman, D. Gandhi, and Vikrant Tomar,\" Multi-hop Multi-band Intelligent Relay-Based Architecture for LTE-Advanced Multi-hop Wireless Cellular Networks\", Springer Wireless Personal Communications, 2013. DOI 10.1007/s11277-013-1352-0</p> </li> <li> <p>Vikrant Tomar, H. Asnani, A. Karandikar, and P. Kapadia, \"Traffic Analysis of a Short Message Service Network\", IEEE NCC 2010</p> </li> <li> <p>Vikrant Tomar, H. Asnani, A. Karandikar, V. Chander, S. Agrawal, and P. Kapadia, \"Social Network Analysis of the Short Message Service\", IEEE NCC 2010 , 29-31 Jan. 2010 DOI: 10.1109/NCC.2010.5430162</p> </li> <li> <p>Vikrant Tomar, D. Gandhi and C. Vijaykumar, \"Digital Signal Processing for Gene Prediction\", TENCON 2008 - 23rd IEEE Region 10 Conference, 19-21 Nov. 2008, Hydrabad, India, 2008. DOI: 10.1109/TENCON.2008.4766648</p> </li> </ul>"},{"location":"publications/#other-publicationsreports","title":"Other Publications/Reports","text":"<ul> <li> <p>Vikrant Singh Tomar, \"Speaker Variability in Automatic Speech Recognition\"</p> </li> <li> <p>Vikrant Singh Tomar, \"Blind Dereverberation using Maximum Kurtosis of the Speech Residual\" download presentation .pdf</p> </li> <li> <p>Vikrant Singh Tomar, \"Discriminant Feature Space Transformations for Automatic Speech Recognition\" download presentation .pdf</p> </li> </ul>"},{"location":"thought-leadership/","title":"Thought Leadership","text":"<p>Given below are non-comprehensive lists of some of the events/presentations/publications that I have participated in to discuss my thoughts about consumer electronics market, and specfically for voice control devices.</p>"},{"location":"thought-leadership/#talks-and-appearances","title":"Talks and Appearances","text":"<ul> <li>THD podcast, Jun 2021:  On Youtube</li> <li>Talk at TinyML Summit, Apr 2021. Using Neural Architecture Search for Speech Recognition on the Edge</li> <li>Panel at Embedded World Conference organized by Arm, March 2021. Voice Control Made Simple</li> <li>Presentation and Paper at Embedded World Conference, March 2021. \"How to Drive Down the Cost and Power of On-Device Voice-Based Endpoints\". Joint with Kobus Marneweck from Arm.</li> <li>TinyML Webinar Talk, Sept 2020.  TinyML. Building low-power speech recognition solutions</li> <li>Arm AI Webinar, Aug 2020. Building Speech recognition solutions for ARM Cortex M</li> <li>Featured in Digital Trends AI segment, Feb 2020</li> <li>Panelist, Tech Montreal: \"Building World Class Companies\", June 2019</li> <li>Fireside chat at Le Wagon Montreal, May 2019 : -- Video: On Facebook -- Podcast: On Spotify</li> <li>Talk ``Speech Recognition on Devices\", IEEE Montreal, 2018</li> <li>Judge, Google Cloud Sprint, 2018</li> <li>Toronto Tech Summit. Presentation: Speech recognition present and future presentation; and panel: How AI is disrupting CX, 2018</li> <li>Oracle Open World. San Francisco, 2017</li> <li>Talk at Startup Fest Montreal. AI Fest  Talk 2017. Progress and problems in speech recognition</li> </ul> <ul> <li>Startup Fest Montreal, Human Computer Interaction Panel, 2016</li> </ul>"},{"location":"thought-leadership/#articles-and-writeups","title":"Articles and Writeups","text":"<ul> <li>TinyML and Voice Recognition Technology are Transforming Industries, in AudioXpress Magazine, Jan 2022.</li> <li>How Speech Technology Is Optimizing Factory Lines, in IndustryToday, Sep 2021.</li> <li>Voice Command: Multilingual Speech Recognition for the Shop Floor, in Machine Design Magazine, Aug 2021.</li> <li>R&amp;D Stories: Speaker ID Technology, in AudioXpress Magazine, Apr 2021.</li> <li>Contactless Voice Payment Technology: A Retail Strategy for Bringing Customers Back In-Store, in RetailTouchPoints Jun 2021.</li> <li>Q &amp; A with Loudspeaker Industry Sourcebook, Jun 2021.</li> <li>COVID, cashless, and convenience: The rise of biometrics, in FinTech Magazine, May 2021.</li> <li>Interview with Unite.AI, Jan 2021.</li> <li>Globe and Mail Article, Nov 2020.</li> </ul> <p>&lt;!--</p>"},{"location":"thought-leadership/#fluent-related","title":"Fluent related","text":"<ul> <li>Wired: Montreal has reinvented itself as the world's AI startup powerhouse </li> <li>https://www.designnews.com/consumer-electronics/12-best-innovations-ces-2020</li> <li>https://community.arm.com/developer/ip-products/processors/b/ml-ip-blog/posts/fluent-ai-multilingual-speech-recognition-arm-cortex-mcus</li> <li>https://www.globenewswire.com/news-release/2021/06/10/2245377/0/en/Fluent-ai-Launches-Partnership-with-BSH-to-Voice-Automate-the-Assembly-Line-Increasing-Efficiency-and-Improving-Factory-Worker-Ergonomics.html</li> </ul>"}]}